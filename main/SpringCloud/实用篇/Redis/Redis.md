# Redis

## Redis

### 什么是Redis？

- 一个开源（BSD 许可）、基于内存、支持多种数据结构的存储系统，可以作为数据库、缓存和消息中间件。

### Redis和Memcached的区别

- memcached仅支持key-value的数据结构，redis支持更多的数据结构（string,list,hash,sorted set,set）
- redis可以持久化其数据（AOF,RDB）
- 虚拟内存--redis当物理内存用完时，可以将一些很久没用到的value 交换到磁盘
- 都可以一主一从， Memcached 还可用于缓存其他东西，例如图片、视频等
- Memcached是多线程非阻塞式的网络I/O模型；Redis是单线程非阻塞式的网络I/O模型

### Redis的事务

- 定义

	- 一组命令的集合，是 Redis 的最小执行单位。它可以保证一次执行多个命令，每个事务是一个单独的隔离操作，事务中的所有命令都会序列化、按顺序地执行。

- 原理

	- 通过MULTI、EXEC、DISCARD和WATCH 四个原语实现，将事务中的命令序列化，然后顺序执行。
	- 将属于一个事务的命令发送给 Redis，然后依次执行这些命令

- 特性

	- 单独的隔离操作

		- 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

	- 没有隔离级别的概念

		- 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行

	- 不保证原子性

		- 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚

- 实现原语

	- multi

		- 用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。

	- exec

		- 执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。

	- discard

		- 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。

	- watch

		- WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。

	- unwatch

		- 解除监控

- 注意点

	- 1、Redis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行
	- 2、Redis 服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部执行完毕才会执行其他客户端的命令。
	- 3、如果在一个事务中的命令出现错误，那么所有的命令都不会执行（命令参数错误等）
	- 4、如果在一个事务中出现运行错误，那么正确的命令会被执行（例如操作不同）

- 为什么不支持回滚？

	- （1）只有当被调用的Redis命令有语法错误时，或者对某个键执行不符合其数据类型的操作，这条命令才会执行失败。但是如果出现其他问题，则依然会继续执行余下的命令。
	- （2）这些问题可以从程序层面捕获并解决，很少在生产环境发现
	- （3）回滚需要增加很多工作，而不支持回滚则可以保持简单、快速的特性。

- 秒杀案例

	- 产生的问题

		- 超时

			- 每个线程调用redis都要使用jedis连接，导致连接超时
			- 解决方案

				- 线程池

		- 超卖

			- 定义

				- 多线程下操作数据，虽然数据已经为空，有些线程还在进行，继续操作导致

			- 解决方案

				- 使用redis事务(watch)

					- 库存数量被修改，执行失败

				- redis分布式锁

					- setex加锁并且自动释放锁

				- redis队列（rpoplpush的安全队列）

					- 把每一件商品都lpush到redis队列中，利用lpop从队列中去取

		- 一人一单

			- 用户重复下单
			- 解决方案

				- 用户下单成功后将用户id存入一个set集合，每次下单前判断用户是否已经购买
				- 使用Lua脚本，从判断库存是否充足，到判断是否重复下单（ismember），再到扣减库存都要成为原子性的操作

		- 库存遗留

			- 定义

				- 使用redis事务时，采用的是乐观锁，当某个线程将数据修改后把版本号+1，后续其它线程会因为版本不一致而无法对数据进行修改

			- 解决方案

				- 使用LUA脚本

					- 将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。提升性能
					- LUA脚本是类似redis事务，有一定的原子性，不会被其他命令插队，可以完成一些redis事务性的操作
					- lua脚本解决争抢问题，实际上是redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题

	- Jedis连接池

		- 参数

			- MaxTotal

				- 控制一个pool可分配多少个jedis实例

			- maxIdle

				- 制一个pool最多有多少个状态为idle(空闲)的jedis实例

			- MaxWaitMillis

				- 表示取一个jedis实例时，最大的等待毫秒数

			- testOnBorrow

				- 获得一个jedis实例的时候是否检查连接可用性（ping()）

### Redis的数据类型

- String

	- 定义

		- String类型是二进制安全的，意思是redis的string可以包含任何数据，比如jpg图片或者序列化的对象。
		- 一个Redis中字符串value最多可以是512M

	- 数据结构

		- 简单动态字符串（Simple Dynamic String)

			- 一个带长度信息的字节数组(防止对字节数组进行遍历来获取长度，O(n))
			- 内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配.
			- 内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。

		- Length<1M：2倍  Length>1M：最多1M

	- 使用场景

		- 计数器
		- 用户登录次数
		- 对象缓存存储

			- JSON 序列化对象信息

	- 优点

		- 常数复杂度获取字符串长度
		- 二进制安全

			- 通过 len属性的值来判断是否结束，而不是C字符串的 \0 作为结束

		- 减少修改字符串长度时所需的内存重分配次数

			- 如果新字符串小于1M，则新空间为扩展后字符串长度的两倍+1
			- 如果新字符串大于1M，则新空间为扩展后字符串长度+1M+1。称为内存预分配

		- API安全，杜绝缓冲区溢出

			- SDS 在进行字符串拼接时，会先检查 len 的长度是否足够，如果不够，会先扩展 len，再进行字符串拼接
			- 防止忘记扩展内存

	- 注意事项

		- 1、基本编码方式是RAW，基于简单动态字符串（SDS）实现
		- 2、如果存储的SDS长度小于44字节，则会采用EMBSTR编码，此时object head与SDS是一段连续空间（效率更高）
		- 3、如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用INT编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节）

- List

	- 定义

		- 它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。
		- 简单的字符串列表，按照插入顺序排序

	- 数据结构

		- 压缩列表

			- 定义

				- 一系列特殊编码的连续内存块组成的顺序型数据结构
				- 每个节点中可以保存相应的数据类型（字节数组或者一个整数值）

			- 构成

				- previous_entry_length

					- 记录了压缩列表中的前一个字节的长度

				- encoding

					- 记录了节点的 content 属性所保存数据的类型以及长度

				- content

					- 负责保存节点的值

			- 连锁更新问题

				- 原因

					- Entry的previous_entry_length

						- 如果前一节点的长度小于254字节，则采用1个字节来保存这个长度值
						- 如果前一节点的长度大于等于254字节，则采用5个字节来保存这个长度值，第一个字节为0xfe

				- 过程

					- 假设有 N 个连续的，长度为 250-253 之间的 entry ,此时 previous_entry_length 属性用一个字节即可记录
					- 当有一个大小为 254 个字节的 entry 插入ZipList 最前面，此时会导致后面 entry 的 previous_entry_length 用 5 个字节来存储当前插入节点的大小
					- 会导致后一个 entry 的大小变得大于或等于 254 个字节，从而引发连锁反应

				- 新增+删除

			- 优点

				- 内存占用低

			- 缺点

				- 申请内存必须是连续空间，如果内存占用较多，申请内存效率很低
				- 如果列表数据过多，导致链表过长，可能影响查询性能
				- 增或删较大数据时有可能发生连续更新问题

		- 快速链表(quickList)

			- 链表和ziplist结合,将多个ziplist使用双向指针串起来使用
			- 优点

				- 控制了ZipList大小，解决连续内存空间申请效率问题
				- 中间节点可以压缩，进一步节省了内存

			- 缺点

		- 列表元素较少时使用zipList，数据量多时才会变成quickList

	- 使用场景

		- 消息排行
		- 消息队列

			- 利用List的PUSH操作，将任务存在List中，然后工作线程再用POP操作将任务取出进行执行

		- 栈、队列
		- 分页功能

- Set

	- 定义

		- string类型的无序集合。它底层其实是一个value为null的hash表，添加，删除，查找的复杂度都是O(1)，所有的value都指向同一个内部值.
		- 可以自动排重的

	- 数据结构

		- 为了查询效率和唯一性，set采用HT编码（Dict）。Dict中的key用来存储元素，value统一为null
		- 当存储的所有数据都是整数，并且元素数量不超过set-max-intset-entries（512）时，Set会采用IntSet编码，以节省内存

	- 使用场景

		- 共同关注

			- 两个set集合做交集，存放关注的用户的id

		- 共同爱好
		- 推荐好友
		- 二度好友

- Hash

	- 定义

		- 一个string类型的field和value的映射表

	- 数据结构

		- ziplist（压缩列表）

			- ZipList中相邻的两个entry 分别保存field和value

		- hashtable（哈希表）
		- 当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable

	- 注意事项

		- 1、当数据量较大时，Hash结构会转为HT编码，也就是Dict

			- ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）
			- ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）

	- 使用场景

		- 对象存储

- 
- Zset

	- 定义

		- 使用了两个数据结构；一个是hash，用于关联元素的value和score，保障元素value的唯一性，可以通过元素value找到相应的score值；另一个是跳跃表，用于给value排序，根据score的范围获取元素列表。
		- 个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员

	- 数据结构

		- hash

			- 关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。

		- 跳跃表(skiplist)

			- 跳跃表是将链表改造支持二分法查找的数据结构
			- 每两个元素抽取一个元素放到上一层，这样依次叠加，就形成了多层的链表。上一层的元素个数是下一层元素个数的1/2，所以查询的时候就类似二分查找。
			- 如果这个节点的指向为NULL或指向的值大于要查找的值，往下一层。

	- 注意事项

		- zset还会采用ZipList结构来节省内存

			- 元素数量小于zset_max_ziplist_entries，默认值128
			- 每个元素都小于zset_max_ziplist_value字节，默认值64

	- 使用场景

		- 排行榜实现

			- 例如点赞排行以系统当前时间为score排序，微信运动排行排行以步数排序

		- 取Top N测试

- Bitmaps

	- 定义

		- 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作
		- Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量

	- 使用场景

		- 统计用户信息状态，活跃
		- 打卡情况
		- 登录状态
		- 用户签到

			- stringRedisTemplate.opsForValue().setBit(key, dayOfMonth - 1, true)

		- 签到统计

			- stringRedisTemplate.opsForValue().bitField(key,
BitFieldSubCommands.create().get(BitFieldSubCommands.BitFieldType.unsigned(LocalDateTime.now().getDayOfMonth())).valueAt(0)

	- setbit、getbit

- Hyperloglog

	- 定义

		- 基数统计的算法
		- 在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。

	- 使用场景

		- 解决求集合中不重复元素个数的问题称为基数问题
		- 统计网页的UV（浏览用户数量，一天内同一个用户多次访问只能算一次）

			- 每次用户访问就把用户id放入Hyperloglog中

- Geospatial

	- 地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度
	- geo的数据类型为zset
	- 将用户给定的地理位置信息储存起来，来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能。

- 子主题 9

	- 

### Reids的同步机制

- Redis 支持主从同步、从从同步。如果是第一次进行主从同步，主节点需要使用 bgsave 命令，再将后续修改操作记录到内存的缓冲区，等 RDB 文件全部同步到复制节点，复制节点接受完成后将RDB 镜像记载到内存中。
- 等加载完成后，复制节点通知主节点将复制期间修改的操作记录同步到复制节点，即可完成同步过程。

### Redis的主从复制

- 定义

	- 主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主
	- 读写分离，性能扩展；容灾快速恢复

- 分类

	- 一主二从
	- 薪火相传

		- 上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求

	- 反客为主

		- 当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改
		-  slaveof  no one ：将从机变为主机

- 实现原理

	- 同步关键

		- Replication Id

			- 简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid

		- offset

			- 偏移量，随着记录在repl_baklog中的数据增多而逐渐增大.slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新.

	- 流程

		- 1、Slave启动成功连接到master后会发送一个sync命令(数据同步消息)，携带replid和offset
		- 2、Master接到命令(同步消息)启动后台的存盘进程，对。

			- 第一次同步（replid不一致）

				- 进行全量复制，返回版本信息(replid、offset)

			- 不是第一次同步

				- 增量复制

		- 4、每次主服务器进行写操作后，都会和从服务器进行数据同步
		- 3、Master生成rdb期间记录所有的命令，存放到repl_baklog文件中，并不断向Slave发送文件中的命令

- 复制类型

	- 全量复制

		- 流程

			- Master执行bgsave命令进行持久化，生成rdb文件，master将传送整个数据文件到slave，Slave清空本地数据并加载rdb文件

		- 时机

			- 1、slave节点第一次连接master节点时
			- 2、slave节点断开时间太久，repl_baklog中的offset已经被覆盖时（未备份数据被覆盖）

	- 增量复制

		- 流程

			- Master继续将repl_log中新的所有收集到的修改命令依次传给slave,完成同步

		- 时机

			- slave节点断开又恢复，并且在repl_baklog中能找到offset时

- slaveof <masterip> <masterport>

### Redis的哨兵模式

- 定义

	- 实现主从集群的自动故障恢复的一种机制，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库

- 作用

	- 监控

		- Sentinel 会不断检查master和slave是否按预期工作

	- 自动故障恢复

		- 如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主

	- 通知

		- Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端

- 服务状态监控

	- 定义

		- Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令

	- 状态

		- 主观下线

			- 如果某sentinel节点发现某实例未在规定时间（down-after-milliseconds * 10）响应，则认为该实例主观下线。
			- 正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态

		- 客观下线

			- 若指定时间内超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。

- 选举策略

	- 一定不选举主观下线的节点
	- 优先选择优先级高的

		- 在redis.conf中默认：slave-priority 100，值越小优先级越高（为0不参与选举）

	- 其次选择偏移量最大的

		- 偏移量

			- 获得原主机数据是否全面

		- 从机的数据越全面，优先选择

	- 最后选择runid最小的

		- runid

			- 每个redis实例启动后都会随机生成一个40位的runid，越小优先级越高

- 故障转移流程

	- 1、sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master
	- 2、sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据
	- 3、最后，sentinel将故障节点标记为slave（配置文件层修改），当故障节点恢复后会自动成为新的master的slave节点

- 恢复过程

	- 1、根据选举策略选举新的主服务
	- 2、哨兵(sentinel)向原主服务的从服务发送salveof的新主服务的命令，复制新的master
	- 3、已下线的主服务上线时自动成为从机

- 实现

	- 新建sentinel.conf文件

		- port 27001
sentinel announce-ip 120.78.230.51
sentinel monitor mymaster 120.78.230.51 7001 quorum
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 60000
dir "/opt/redis/sentinel-7001"

	- quorum > sentinels/2+1
	- mymaster为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量。
	- 执行redis-sentinel  /myredis/sentinel.conf

### Redis的分片集群

- 定义

	- 实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。

- 为什么要使用集群？

	- 主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息
	- 进行redis扩容
	- 存在大量并发写操作时，采用主从模式依然有很大的压力
	- 无中心化配置，使得ip地址可以自动重定向

- 集群配置

	- 修改配置文件

		- cluster-enabled yes    打开集群模式
		- cluster-config-file nodes-6379.conf  设定节点配置文件名
		- cluster-node-timeout 15000   设定节点失联时间，超过该时间（毫秒），集群自动进行主从切换

	- redis-cli --cluster create --cluster-replicas 1 120.78.230.51:7001 120.78.230.51:7002 120.78.230.51:7003 120.78.230.51:8001 120.78.230.51:8002 120.78.230.51:8003

		- --replicas 1 采用最简单的方式配置集群，一台主机，一台从机，正好三组

	- redis-cli -c -p 6379

		- -c 采用集群策略连接，设置数据会自动切换到相应的写主机
		- 尽量用-c登录，不然可能直接进入读主机，存储数据时，会出现MOVED重定向操作
		- –c 参数实现自动重定向到对应的主机进行操作

- 插槽(slots)

	- 定义

		- 一个 Redis 集群包含 16384 (2^14)个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个
		- 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和

	- 计算插槽

		- CRC16(key) % 16384 
		- key中包含"{}"，且“{}”中至少包含1个字符，“{}”中的部分是有效部分
		- key中不包含“{}”，整个key都是有效部分

	- 注意事项

		- 1、不在一个slot下的键值，是不能使用mget,mset等多键操作
		- 2、每次录入、查询键值，redis都会计算出该key应该送往的插槽
		- 3、只能在操作本机的插槽
		- 4、可以通过{}来定义组的概念，从而使key中{}内相同内容的键值对放到一个slot中去

- 故障恢复

	- 如果主节点下线？从节点能否自动升为主节点？注意：15秒超时

		- 主节点恢复后，主从关系会如何？主节点回来变成从机

	- 流程

		- 1、首先是该实例与其它实例失去连接
		- 2、然后是疑似宕机
		- 3、最后是确定下线，自动提升一个slave为新的master

	- cluster-require-full-coverage

		- yes 

			- 如果某一段插槽的主从都挂掉，整个集群都挂掉

		- no

			- 如果某一段插槽的主从都挂掉，该插槽数据全都不能使用，也无法存储

- 数据迁移

	- 定义

		- salve接管master，进行master与slave之间的数据迁移
		- cluster failover

	- 流程

		- 1、slave节点告诉master节点拒绝任何客户端请求
		- 2、 master返回当前的数据offset给slave
		- 3、3.等待数据offset与master一致
		- 4、开始故障转移，标记自己为master，广播故障转移的结果

- 其它命令

	- redis-cli -p 7001 cluster nodes：查看集群信息
	- cluster getkeysinslot <slot><count>：返回 count 个 slot 槽中的键
	- cluster countkeysinslot <slot>：查看插槽中键的数量
	- cluster failover：进行master与slave之间的数据迁移，slave接管master

- 缺点

	- （1）多键操作是不被支持的 
（2）多键的Redis事务是不被支持的。lua脚本不被支持
（3）由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大

### Redis的线程模型

- 为什么redis是单线程的？

	- （1）redis内部使用文件事件处理器(file event handler)，这个文件事件处理器是单线程的。
	- （2）文件事件处理器采用IO多路复用机制同时监听多个socket，根据socket上的事件选择对应的事件处理器进行处理。
	- （3）多线程处理会涉及到锁，并且多线程处理会涉及到线程切换而消耗 CPU。采用单线程，避免了不必要的上下文切换和竞争条件。其次 CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。

- 文件事件处理器

	- 多个socket
	- IO多路复用程序
	- 文件事件分派器

		- 文件事件分派器会优先处理 AE_READABLE事件，等到AE_READABLE事件处理完之后，才处理AE_WRITABLE事件

	- 事件处理器

		- 连接应答处理器
		- 命令请求处理器
		- 命令回复处理器

- redis与客户端的一次通信过程

	- 1.客户端Socket01向Redis的Server Scoket请求建立连接，此时Server Socket产生一个AE_READABLE事件，IO多路复用程序监听到Server socket产生的事件后，将该事件压入队列。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器创建能与客户端通信的Socket01，并将该Socket01的AE_READABLE事件与命令请求处理器关联。
	- 2.假设此时客户端发送一个set key value请求，此时Redis的Socket01会产生AE_READABLE事件，IO多路复用程序将事件压入队列，事件分派器从中获取该事件，交给命令请求处理器(redis的Socket01的AE_READABLE已经与命令请求器关联)，命令请求处理器读取这个请求并在自己的内存中完成set key value的设置。操作完成后，将Socket01的AE_WRITABLE事件与命令回复处理器关联。
	- 3.如果此时客户端准备好接受返回结果了，Redis中的Socket01会产生一个AE_WRITABLE事件，将其压入队列中，事件分派器找到相关联的命令回复器，命令回复器对Socket01输入本次操作的一个结果(ok)，之后解除Socket01的AE_WRITABLE事件与命令回复器的关联。

- 文件事件

	-  AE_READABLE/AE_WRITABLE
	- 服务器则通过监听并处理这些事件来完成一系列网络通信 操作

-  AE_READABLE/AE_WRITABLE的产生

	- 如果套接字的读事件正在被监听，那么函数返回AE_READABLE
	- 如果套接字的写事件正在被监听，那么函数返回AE_WRITABLE
	- 当套接字变得可读时（客户端对套接字执行write操作，或者执行close操作），或者有新的可应答（acceptable）套接字出现时（客户端对服务器的监听套接字执行connect操 作），套接字产生AE_READABLE事件。
	- 套接字变得可写时（客户端对套接字执行read操作），套接字产生AE_WRITABLE事 件

- IO多路复用程序

	- 定义

		- IO多路复用：是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。

	- 实现

		- Redis的I/O多路复用程序的所有功能都是通过包装常见的select、epoll、evport和kqueue 这些I/O多路复用函数库来实现的

- 文件描述符（File Descriptor）

	- 简称FD，是一个从0 开始的无符号整数，用来关联Linux中的一个文件。在Linux中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）

- 事件通知机制

	- 分类

		- LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。
		- EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。

### Redis的持久化机制

- 定义

	- 将数据从内存同步到磁盘中
	- 单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程出，内存释放。

- 分类

	- RDB

		- 定义

			- 按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。

		- 过程

			- 单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程出，内存释放。（写时复制技术 bgsave）

		- 优缺点

			- 优点

				- （1）只有一个文件 dump.rdb ，方便持久化。
（2）容灾性好，一个文件可以保存到安全的磁盘。
（3）性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能
（4）相对于数据集大时，比 AOF 的启动效率更高。

			- 缺点

				- 数据安全性低。 RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失
				- 内存中的数据被复制了一遍，内存需要足够大

		- 动态停止RDB

			- redis-cli config set save "" #save后给空值，表示禁用保存策略

		- 写时复制(copy-on-write)

			- 当主进程写操作时，首先会复制一份将要涉及写操作的内存页。然后主进程在新复制的内存页上进行写操作，原有内存页继续供子进程持久化

	- AOF

		- 定义

			- 指所有的命令行记录以 Redis 命令请求协议的格式完全持久化存储，保存为 AOF 文件
			- 每条会使 Redis 内存数据发生改变的命令都通过Write函数追加到文件最后，Redis每次重启都会读取AOF文件进重构数据

		- 过程

			- 1、客户端的请求写命令会被append追加到AOF缓冲区内；
			- 2、AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中
			- 3、AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量
			- 4、Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的

		- 优缺点

			- 优点

				- （1）数据安全， AOF 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 AOF 文件中一次。
（2）通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。
（3）AOF 机制的 rewrite 模式。 AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall )

			- 缺点

				- （1）AOF 文件比 RDB 文件大，且恢复速度慢。
（2）数据集大的时候，比 RDB 启动效率低。

		- 持久化策略(同步频率)

			- appendfsync always

				- 始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好

			- appendfsync everysec

				- 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失

			- appendfsync no

				- redis不主动进行同步，把同步时机交给操作系统

		- 重写(rewrite)

			- 目的

				- 压缩AOF文件容量

			- 条件

				- 超过重写策略

					- auto-aof-rewrite-percentage 100 # AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-min-size 64mb # AOF文件体积最小多大以上才触发重写 

				- 手动重写

					- bgwriteaof

			- 过程

				- 1、bgrewriteaof触发重写，判断是否当前有bgsave(写命令)或bgrewriteaof(重写)在运行，如果有，则等待该命令结束后再继续执行。
				- 2、主进程fork出子进程执行重写操作，保证主进程不会阻塞。
				- 3、子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。
				- 4、1)子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入(追加)到新的AOF文件。
				- 5、使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。

- 如何选择

	- 1、不要仅仅使用 RDB ，因为那样会导致你丢失很多数据。
	- 2、 也不要仅仅使用 AOF ，因为那样有两个问题，第一，你通过 AOF 做冷备没有 RDB 做冷备的恢复速度更快; 第二， RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug。
	- 3.、Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。
	- 4、如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 AOF 来重新构建数据，因为 AOF 中的数据更加完整。
	- 5、同时开启会默认使用AOF

### Redis的过期策略以及内存淘汰机制

- 过期策略

	- 定时删除

		- 用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略。
		- 会导致很多key到时间没有删除

	- 惰性删除

		- 获取某个key时，Redis会检查这个key是否设置了过期时间并进行相应处理（过期了才删除）。

	- 周期删除

		- 通过一个定时任务，周期性的抽样部分过期的key，然后执行删除
		- 分类

			- Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOW
			- Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST

- Redis采用定时删除+惰性删除策略

	- （1）Redis每隔一段时间随机抽取一定数量的key进行检查，如果有过期的key就删除，并且采用惰性删除。获取某个key时，Redis会检查这个key是否设置了过期时间并进行相应处理。
	- （2）如果定期删除没删除key，并且没有即时去请求key，也就是说惰性删除也没生效，导致Redis的内存越来越高。

- 缓存刷新（内存淘汰）策略

	- 分类

		- volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
		- volatile-lfu： 对设置了TTL的key，基于LFU算法进行淘汰
		- volatile-ttl：从已设置过期时间的数集（server.db[i].expires）中挑选将要过期的数据淘汰
		- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
		- allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
		- allkeys-lfu： 对全体key，基于LFU算法进行淘汰
		- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
		- no-enviction（驱逐）：不淘汰任何key，但是内存满时不允许写入新数据（默认）

	- 算法

		- LRU（Least Recently Used）

			- 最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高

		- LFU（Least Frequently Used）

			- 最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高

- 

### BigKey

- 定义

	- 指键值占用内存空间非常大的 key(>10K)

- 例子

	- 1、数据过大

		- 一个String类型的Key，它的值为5MB

	- 2、列表数量过多

		-  一个List类型的Key，它的列表数量为20000个

	- 3、成员数量过多

		- 一个ZSet类型的Key，它的成员数量为10000个

	- 4、成员体积过大

		-  一个Hash格式的Key，它的成员数量虽然只有1000个但这些成员的value总大小为100MB

- 发现

	- 1、redis-cli --bigkeys

		- 返回Key的整体统计信息与每个数据的Top1的big key

	- 2、scan扫描

		- 利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度

	- 3、第三方工具

		- 如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况

	- 4、网络监控

		- 自定义工具，监控进出Redis的网络数据，超出预警值时主动告警

- 删除

	-  redis 3.0 及以下版本，如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey
	-  Redis在4.0后提供了异步删除的命令：unlink

- 影响

	- 1、网络阻塞

		- 获取 bigkey 时，传输的数据量比较大，会增加带宽的压力

	- 2、超时阻塞

		- 因为 bigkey 占用的空间比较大，所以操作起来效率会比较低，导致出现阻塞的可能性增加

	- 3、导致内存空间不平衡(数据倾斜)

		- BigKey所在的Redis实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡

	- 4、CPU压力

		- 对BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用

### 单点Redis的问题及解决方案

- 数据丢失问题

	- 实现Redis数据持久化

- 并发能力问题

	- 搭建主从集群，实现读写分离

- 故障恢复问题

	- 利用Redis哨兵，实现健康检测和自动恢复

- 存储能力问题

	- 搭建分片集群，利用插槽机制实现动态扩容

### 什么是 bigkey？会存在什么影响？

- 定义

	- 指键值占用内存空间非常大的 key

### 为什么要用Redis？

- 高性能

	- 将数据进行缓存放入内存，直接操作缓存就是操作内存，速度快

- 高并发

	- 支持多种数据结构，包括字符串、列表、集合、有序集合、哈希等

- 直接操作缓存能够承受的请求是远远大于直接访问数据库的
- 支持事务，且操作遵守原子性，即对数据的操作要么都执行，要么都不支持
- 拥有其他丰富的功能，队列、主从复制、集群、数据持久化等功能

### 为什么Redis这么快？

- C语言实现，效率高
- 纯内存数据库
- 单线程数据库

	- 不需要创建/销毁线程，避免上下文切换，无并发资源竞争的问题

- 非阻塞式I/O复用模型(多路复用IO技术)

	- “多路”指多个网络连接；"复用"指复用一个线程；多路复用IO技术可以让单线程高效的处理多个连接请求。

### 为什么Redis的key最大为512MB?

- redis存在sdshdr64，但是为了防止bigkey，在底层对key的大小进行了限制，只能使用到sdshdr32（2^32/8/1024/1024=512m）

### 为什么Redis这么快？

### 为什么 Redis 把所有数据放到内存中？

- 可以实现最快的对数据读取，如果数据存储在硬盘中，磁盘 I/O 会严重影响 Redis 的性能。而且 Redis 还提供了数据持久化功能，不用担心服务器重启对内存中数据的影响。其次现在硬件越来越便宜的情况下，Redis 的使用也被应用得越来越多，使得它拥有很大的优势

### 为什么要用 pipeline？

- 可以将多次 I/O 往返的时间缩短为一次，但是要求管道中执行的指令间没有因果关系
- 可以实现请求/响应服务器的功能，当客户端尚未读取旧响应时，它也可以处理新的请求。如果客户端存在多个命令发送到服务器时，那么客户端无需等待服务端的每次响应才能执行下个命令，只需最后一步从服务端读取回复即可

### 为什么Redis的操作是原子性的，怎么保证原子性的？

- 因为Redis是单线程的，事务是Redis执行的最小单位，事务是隔离的。对Redis来说，执行API就是一个任务。在单线程程序中，任务一个一个地做，必须做完一个任务后，才会去做另一个任务。 
- Redis本身提供的所有API都是原子操作，Redis中的事务其实是要保证批量操作的原子性。
- 多个命令在并发中也是原子性的吗？

	- 不一定， 将get和set改成单命令操作(incr)，或者使用Redis的事务(Watch)，或者使用Redis+Lua的方式实现

### Redis产生的问题及解决方案？

- 分布式锁

	- 分类

		- 线程锁

			- 主要用来给方法、代码块加锁，只在同一个JVM中有效
			- 线程锁的实现在根本上是依靠线程之间共享内存实现的

		- 进程锁

			- 为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过synchronized等线程锁实现进程锁

		- 分布式锁

			- 当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问

	- Redis实现分布式锁

		- set key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp |KEEPTTL] [NX|XX] [GET]
		- setnx加锁，设置时间自动释放锁

	- 分布式锁可用的条件

		- 1、互斥性。在任意时刻，只有一个客户端能持有锁
		- 2、不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁
		- 3、加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了
		- 4、加锁和解锁必须具有原子性

	- 优化

		- setnx设置锁的过期时间

			- 自动释放锁
			- 问题

				- 可能会删除其它锁
				- 子主题 2

		- 设置uuid防止误删

			- setnx获取锁时，设置一个指定的唯一值（例如：uuid）；释放前获取这个值，判断是否自己的锁的uuid与锁的uuid是否相同
			- 问题

				- 删除没有原子性；
				- 比较uuid相等后，正要删除锁的时候，锁的过期时间到了，自动释放锁，其它线程能够得到这个锁并上锁，但是上一个线程的删除操作还在进行，可能会删除这个线程的锁。

		- LUA脚本保证删除的原子性

			- 保证从判断锁到删除锁都是原子性的

- 缓存雪崩

	- 定义

		- 由于原有缓存失效，新缓存未到期间，我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。

	- 解决方案

		- 1、分散缓存失效时间，随机
		- 2、采用加锁或队列的方式防止大量的线程对数据库一次性进行读写
		- 3、构建多级缓存架构：nginx缓存 + redis缓存 +其他缓存（ehcache等)
		- 4、设置过期标志更新缓存

			- 记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。

- 缓存穿透

	- 定义

		- 用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，导致数据库压力过大，这也是经常提的缓存命中率问题。

	- 解决方案

		- 1、缓存空对象

			- 如果一个查询返回的数据为空，仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。下次访问得到的是空数据。

		- 2、实时监控
		- 3、布隆过滤器

			- 数据结构

				- 一个 bit 向量或者说 bit 数组或者bitmap + 一系列哈希函数
				- 将所有可能存在的数据哈希到一个足够大的bitmap

			- 过程

				- 先将位数组初始化，每个位置为0。对集合的每个元素通过n个哈希函数进行映射，产生n个哈希值，将位数组对应的位置置1。
				- 查询某个元素是否在集合中时，将这个元素通过哈希映射到位数组上，如果其中一个位不为1，则该元素不存在。

			- 为什么会产生误判？

				- 哈希函数具有不确定性，位数组的某个位上的1可能是多个元素共同映射的，不能判断某个元素一定在集合中，但能判断某个元素一定不在集合中。

			- 一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力

- 缓存击穿

	- 定义

		- 某一个热点 key，在缓存过期的一瞬间，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

	- 解决方案

		- （1）设置热点数据永不过期

			- 直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存

		- （2）实时调整

			- 现场监控哪些数据热门，实时调整key的过期时长

		- （3）加互斥锁

			- 只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。

				- 性能较差，线程阻塞

- 缓存预热

	- 定义

		- 系统上线后，将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据。

	- 解决方案

		- 1、直接写个缓存刷新页面，上线时手工操作下
		- 2、数据量不大，可以在项目启动的时候自动进行加载
		- 3、定时刷新缓存

- 缓存降级

	- 定义

		- 访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。
		- 缓存失效或者缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或者访问服务的内存数据

			- 比如双十一的时候淘宝购物车无法修改地址只能使用默认地址

	- 目的

		- 保证核心服务可用，即使是有损的
		- 防止Redis服务故障，导致数据库跟着一起发生雪崩问题

### 什么是发布订阅？

- 定义

	- 一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。
	- Redis 客户端可以订阅任意数量的频道

- 一个Redis中字符串value最多可以是512M
- subscribe chanel01；
publish chanel01 hello；

### Redis内存不足？

- 修改配置文件 redis.conf 的 maxmemory 参数，增加 Redis 可用内存
- 设置缓存淘汰策略，提高内存的使用效率
- 使用 Redis 集群模式，提高存储量

### 如何解决key冲突？

- Redis 如果 key 相同，后一个 key 会覆盖前一个 key
- 最好给 key 取好名区分开，可以按业务名和参数区分开取名，避免重复 key 导致的冲突

### 如何提高缓存命中率？

- 定义

	- 缓存命中率=从缓存中读取的次数/总读取次数

- 解决方案

	- 提前加载数据到缓存中
	- 增加缓存的存储空间，提高缓存的数据
	- 调整缓存的存储数据类型
	- 提升缓存的更新频率

### keys和scan的区别？

- keys

	- 对键进行全量扫描
	- KEYS pattern
	- 缺点

		- 数据量大时执行时间长

- scan

	- 渐进式遍历键
	- SCAN cursor [MATCH pattern] [COUNT count]
	- 注意事项

		- 当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束.
		- 返回的数量不一定
		- 扫描的机构可能是重复的key
		- 每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程.

- 区别

	- keys会阻塞主线程；scan分批次扫描，不会阻塞主线程
	- scan查找的数据可能存在重复，需要客户端操作去重

### 是否使用过 Redis Cluster 集群，集群的原理是什么？

- 1、所有的节点相互连接

### Redis Cluster 集群方案什么情况下会导致整个集群不可用？

- Redis 没有使用哈希一致性算法，而是使用哈希槽。
- 有 A，B，C 三个节点的集群,在没有复制模型的情况下,如果节点 B 失败了，那么整个集群就会以为缺少 5501-11000 这个范围的槽⽽不可⽤。
- cluster-require-full-coverage

	- yes 

		- 如果某一段插槽的主从都挂掉，整个集群都挂掉

	- no

		- 如果某一段插槽的主从都挂掉，该插槽数据全都不能使用，也无法存储

### Redis 常见性能问题和解决方案有哪些？

- 1、Master 最好不要做任何持久化工作

	- 如果 Master 写内存快照，save 命令调度 rdbSave函数，会阻塞主线程的⼯作，当快照⽐较⼤时对性能影响是⾮常⼤的，会间断性暂停服务。

- 2、为了主从复制的速度和连接的稳定性，Master 和 Slave 最好在同一个局域网内
- 3、尽量避免在压力很大的主库上增加从库
- 4、主从复制不要用图状结构，用单向链表结构更为稳定

	- Master宕机可以立即启用Slave做Master

### 什么情况下可能会导致 Redis 阻塞？

- 内部原因

	- 如果 Redis 主机的 CPU 负载过高，也会导致系统崩溃；
	- 数据持久化占用资源过多；
	- 对 Redis 的 API 或指令使用不合理，导致 Redis 出现问题

- 外部原因

	- 服务器的原因，例如服务器的 CPU 线程在切换过程中竞争过大，内存出现问题、网络问题等。

### 怎么使用 Redis 实现消息队列？

- 一般使用 list 结构作为队列， rpush 生产消息， lpop 消费消息。当 lpop 没有消息的时候，要适当sleep 一会再重试。
- list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。
- 用 pub / sub 主题订阅者模式，可以实现1：N的消息队列

### pub / sub 有什么缺点？

- 在消费者下线的情况下，生产的消息会丢失

###  Redis 如何实现延时队列？

- 定义

	- sortedset ，拿时间戳作为 score ，消息内容作为 key， 调用 zadd 来生产消息，消费者用zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。

- 实现

	- String _KEY = "myDelayQueue";
jedis.zadd(_KEY, Instant.now().plusSeconds(2).getEpochSecond(), "order_2");
jedis.zadd(_KEY, Instant.now().plusSeconds(2).getEpochSecond(), "order_3");
	// 当前时间
	Instant nowInstant = Instant.now();
	long lastSecond = nowInstant.plusSeconds(-1).getEpochSecond(); // 上一秒时间
	long nowSecond = nowInstant.getEpochSecond();
	// 查询当前时间的所有任务
	Set<String> data = jedis.zrangeByScore(_KEY, lastSecond, nowSecond);
	for (String item : data) {
		// 消费任务
		System.out.println("消费：" + item);
	}
	// 删除已经执行的任务
	jedis.zremrangeByScore(_KEY, lastSecond, nowSecond);
	Thread.sleep(1000); // 每秒轮询一次

### Redis 是单线程还是多线程？

- Redis 是单线程，主要是指 Redis 对外提供键值存储服务的主要流程，即网络 IO 和键值对读写是由⼀个线程来完成
- 比如持久化、 异步删除、集群数据同步等，是由额外的线程执⾏

### select、poll、epoll的区别？

- 消息传递方式

	- select+poll：内核需要将消息传递到用户空间，都需要内核拷贝动作
	- epoll：通过内核和用户空间共享一块内存来实现的

- 效率

	- select+poll：只会通知用户进程有FD就绪，但不确定具体是哪个FD，需要用户进程逐个遍历FD来确认
	- epoll：会在通知用户进程FD就绪的同时，把已就绪的FD写入用户空间(利用ep_poll_callback机制来监听FD状态)

- 一个进程所能打开的最大连接数（FD）

	- select：单个进程所能打开的最大连接数有FD_SETSIZE（1024）宏定义
	- poll：poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储
	- epoll：使用红黑树保存要监听的FD

### save和bgsave的区别？

- save：在主线程中执行，会导致阻塞
- bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞

### Redis 是单线程还是多线程？

## 自由主题

